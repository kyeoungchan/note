# 💻 활용 사례
- [`sorted set`을 이용한 실시간 리더보드](#-sorted-set을-이용한-실시간-리더보드)
  - [데이터 업데이트](#-데이터-업데이트)
  - [랭킹 합산](#-랭킹-합산)
- [`serted set`을 이용한 최근 검색 기록](#-serted-set을-이용한-최근-검색-기록)
- [`set`을 이용한 태그 기능](#-set을-이용한-태그-기능)
- [랜덤 데이터 추출](#-랜덤-데이터-추출)
- [레디스에서의 다양한 카운팅 방법](#-레디스에서의-다양한-카운팅-방법)
  - [좋아요 처리하기](#좋아요-처리하기)
  - [읽지 않은 메시지 수 카운팅하기](#-읽지-않은-메시지-수-카운팅하기)
  - [DAU 구하기](#-dau-구하기)
  - [`hyperloglog`를 이용한 애플리케이션 미터링](#-hyperloglog를-이용한-애플리케이션-미터링)
- [`Geospatial Index`를 이용한 위치 기반 애플리케이션 개발](#-geospatial-index를-이용한-위치-기반-애플리케이션-개발)
  - [레디스에서의 위치 데이터](#-레디스에서의-위치-데이터)

## ✅ `sorted set`을 이용한 실시간 리더보드
리더보드에는 두 가지 유형이 있다.
- 절대적 리더보드(absolute leaderboard): 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시
- 상대적 리더보드(relative leaderboard): 사용자의 스코어를 기반으로 다른 사용자와 비교해 순위를 결정하는 형태의 리더보드
  - 사용자가 속한 그룹 내에서 또는 다른 특정 경쟁자와의 스코어 대결에서 상대적인 순위를 제공한다.

레디스의 `sorted set`을 이용하면 데이터는 저장될 때부터 정렬돼 들어가기 때문에 리더보드의 데이터를 읽어오기 위해 매번 데이터를 정렬할 필요가 없다.

```redis
// daily-score:251115에 플레이어 별 점수 입력
127.0.0.1:6379> ZADD daily-score:251115 28 player:286
(integer) 1
127.0.0.1:6379> ZADD daily-score:251115 400 plyaer:234
(integer) 1
127.0.0.1:6379> ZADD daily-score:251115 45 plyaer:101
(integer) 1
127.0.0.1:6379> ZADD daily-score:251115357 plyaer:24
(error) ERR wrong number of arguments for 'zadd' command
127.0.0.1:6379> ZADD daily-score:251115 357 plyaer:24
(integer) 1
127.0.0.1:6379> ZADD daily-score:251115 199 plyaer:143
(integer) 1

// 플레이어 전체 점수에 따른 오름차순 정렬 출력
127.0.0.1:6379> ZRANGE daily-score:251115 0 -1 withscores
 1) "player:286"
 2) "28"
 3) "plyaer:101"
 4) "45"
 5) "plyaer:143"
 6) "199"
 7) "plyaer:24"
 8) "357"
 9) "plyaer:234"
10) "400"

// 상위 3위까지 플레이어 점수 출력
127.0.0.1:6379> ZREVRANGE daily-score:251115 0 2 withscores
1) "plyaer:234"
2) "400"
3) "plyaer:24"
4) "357"
5) "plyaer:143"
6) "199"
```
- `ZRANGE`: 스코어가 낮은 순서부터 출력한다.
- `ZREVRANGE`: 스코어가 높은 순서부터 출력한다.

### ❗️ 데이터 업데이트
데이터를 업데이트해야 한다면 다음 커맨드로 쉽게 변경이 가능하다.
```redis
127.0.0.1:6379> ZADD daily-score:251115 200 player:286
(integer) 0
127.0.0.1:6379> ZREVRANGE daily-score:251115 0 2 withscores
1) "plyaer:234"
2) "400"
3) "plyaer:24"
4) "357"
5) "player:286"
6) "200"
```
`sorted set`은 기본적으로 `set`이기 때문에 데이터는 중복으로 저장되지 않으며, 같은 아이템을 저장하고자 할 때 스코어가 다르면 기존 데이터의 스코어만 신규 입력한 스코어로 입력된다.

<br>

```redis
127.0.0.1:6379> ZINCRBY daily-score:251115 100 plyaer:24
"457"
127.0.0.1:6379> ZREVRANGE daily-score:251115 0 2 withscores
1) "plyaer:24"
2) "457"
3) "plyaer:234"
4) "400"
5) "player:286"
6) "200"

// 참고로 처음에 데이터를 입력할 때부터 player:234가 아니라 plyaer:234 오타를 쳐서 왜 작동 안하지 싶었다.
127.0.0.1:6379> ZRANGE daily-score:251115 0 -1 withscores
 1) "plyaer:101"
 2) "45"
 3) "player:24"
 4) "100"
 5) "plyaer:143"
 6) "199"
 7) "player:286"
 8) "200"
 9) "plyaer:24"
10) "457"
11) "plyaer:234"
12) "400"
```
직접 스코어를 지정하지 않고 `ZINCRBY` 커맨드를 통해 스코어를 증감시킬 수 있다.  

> 관계형 데이터베이스만 이용해 실시간 차트 서비스를 구현하는 것은 까다로운 작업이다.  
> 모든 유저의 변경 데이터는 실시간으로 업데이트돼야 하며, 점수별로 데이터를 정렬해서 가져오는 작업 자체가 관계형 데이터베이스에 상당한 부하를 줄 수 있기 때문이다.

### ❗️ 랭킹 합산
1. 주간 리더보드는 매주 월요일마다 초기화된다고 가정해보자.
2. 25년 12일은 수요일이다.
3. 이날의 주간 리더보드를 확인하려면 10~12일 스코어를 모두 합산해야한다.

> 관계형 데이터베이스에서 이런 주간 누적 랭킹을 구현하려면 하나의 테이블에서 일자에 해당하는 데이터를 모두 가져온 뒤 선수별로 합치고, 이를 다시 정렬하는 작업을 진행해야 할 것이다.


`ZUNIONSTORE`: 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드다.

```redis
// 25.11.10 sorted set 세팅
127.0.0.1:6379> ZADD daily-score:251110 50 player:101 250 player:24
(integer) 2
127.0.0.1:6379> ZRANGE daily-score:251110 0 -1 WITHSCORES
1) "player:101"
2) "50"
3) "player:24"
4) "250"

// 25.11.11 sorted set 세팅
127.0.0.1:6379> ZADD daily-score:251111 200 player:286 350 player:24 400 player:234
(integer) 3
127.0.0.1:6379> ZRANGE daily-score:251111 0 -1 WITHSCORES
1) "player:286"
2) "200"
3) "player:24"
4) "350"
5) "player:234"
6) "400"

// 25.11.12 sorted set 세팅
127.0.0.1:6379> ZADD daily-score:251112 50 player:24 100 player:101 250 player:234
(integer) 3
127.0.0.1:6379> ZRANGE daily-score:251112 0 -1 WITHSCORES
1) "player:24"
2) "50"
3) "player:101"
4) "100"
5) "player:234"
6) "250"
```

<br>

`ZUNIONSTORE <생성할 키 이름> <합산할 키 개수> <합산할 키>...`로 구조가 이루어진다.
```redis
127.0.0.1:6379> ZUNIONSTORE weekly-score:251112 3 daily-score:251110 daily-score:251111 daily-score:251112
(integer) 4

// 3일 치의 점수가 합산된 데이터가 정렬돼 있다.
127.0.0.1:6379> ZREVRANGE weekly-score:251112 0 -1 WITHSCORES
1) "player:24"
2) "650"
3) "player:234"
4) "650"
5) "player:286"
6) "200"
7) "player:101"
8) "150"
```

<br>

`ZUNIONSTORE` 이용할 때 스코어에 가중치도 줄 수 있다.  
만약 25.11.11에 빼빼로데이 기념 2배 이벤트가 적용된다고 가정해보자(빼빼로데이랑 그거랑 뭔 상관인지는 따지지 말자 나도 잘 모르겠다).

```redis
// WEIGHTS 옵션을 이용해 가중치를 줄 수 있다.
127.0.0.1:6379> ZUNIONSTORE weekly-score:251112 3 daily-score:251110 daily-score:251111 daily-score:251112 WEIGHTS 1 2 1
(integer) 4

127.0.0.1:6379> ZREVRANGE weekly-score:251112 0 -1 WITHSCORES
1) "player:234"
2) "1050"
3) "player:24"
4) "1000"
5) "player:286"
6) "400"
7) "player:101"
8) "150"
```

<br>

## ✅ `serted set`을 이용한 최근 검색 기록
**요구 사항**
- 유저별로 다른 키워드 노출
- 검색 내역은 중복 제거
- 가장 최근 검색한 5개의 키워드만 사용자에게 노출

> 관계형 데이터베이스의 테이블에 데이터를 저장한다면 다음과 같은 쿼리문이 필요하게 된다.  
> `SELECT * FROM keyword WHERE user_id = '123' ORDER BY reg_date DESC LIMIT 5;`  
> - 테이블에 저장할 때는 기존에 사용자가 같은 키워드를 검색했었는지 확인한 후 업데이트해주어야 한다.
> - 테이블에 데이터가 무기한으로 쌓이는 것을 방지하기 위해 주기적으로 배치 작업을 돌려 오래된 검색 기록은 삭제해야 한다.
> - 데이터를 가져올 때는 검색한 시점을 기준으로 정렬해야하기 때문에 사용자와 검색 기록이 늘어날수록 많은 데이터를 테이블에서 관리해야한다는 단점이 있다.

```redis
// 데이터 셋팅
127.0.0.1:6379> ZADD search-keyword:123 20251114220913 실버  
(integer) 1
127.0.0.1:6379> ZADD search-keyword:123 20251114220954 에나멜   202511142210002 반지갑 20251115143501 코듀로이 20251115152734 기모후드 
(integer) 4
// 반지갑 데이터 오타쳐서 업데이트
127.0.0.1:6379> ZADD search-keyword:123 20251114221002 반지갑
0

// 가장 최근 5개 데이터 조회
127.0.0.1:6379> ZREVRANGE search-keyword:123 0 4 WITHSCORES
기모후드
20251115152734
코듀로이
20251115143501
반지갑
20251114221002
에나멜
20251114220954
실버
20251114220913
```

<br>

데이터가 6개째 저장되었을 때 가장 오래된 데이터인 0번 인덱스의 데이터를 삭제하면 된다.  
하지만 매번 데이터를 저장할 때 아이템의 개수를 확인해야하는 것이 번거롭다.  
`sorted set`의 음수 인덱스를 사용해서 데이터를 삭제한다면 번거로움을 줄일 수 있다.
```redis
실버 ➡ -6번 인덱스
20251114220913

에나멜 ➡ -5번 인덱스
20251114220954

반지갑 ➡ -4번 인덱스
20251114221002

코듀로이 ➡ -3번 인덱스
20251115143501

기모후드 ➡ -2번 인덱스
20251115152734

버킷햇 ➡ -1번 인덱스
20251115165302
```

<br>

항상 `ZADD`로 데이터를 저장할 때마다 음수 인덱스 -6번째를 삭제하는 로직을 추가하면 유저별 아이템의 개수를 확인하지 않더라도 5개 이상의 데이터가 저장되지 않도록 강제할 수 있다.  
`ZREMRANGEBYRANK key start stop` 커맨드를 사용하면 인덱스의 범위로 아이템을 삭제할 수 있다.

```redis
// 버킷햇 검색
127.0.0.1:6379> ZADD search-keyword:123 20251115165302 버킷햇
1

// -6번째 인덱스 삭제
127.0.0.1:6379> ZREMRANGEBYRANK search-keyword:123 -6 -6
1

// 상위 5개 최근 검색어 조회
127.0.0.1:6379> ZREVRANGE search-keyword:123 0 4 WITHSCORES
버킷햇
20251115165302
기모후드
20251115152734
코듀로이
20251115143501
반지갑
20251114221002
에나멜
20251114220954

// 전체 데이터 조회
127.0.0.1:6379> ZRANGE search-keyword:123 0 -1 WITHSCORES
에나멜
20251114220954
반지갑
20251114221002
코듀로이
20251115143501
기모후드
20251115152734
버킷햇
20251115165302
```

<br>

## ✅ `set`을 이용한 태그 기능
블로그에 게시물을 작성할 때 태그를 추가하고자 한다.  

> 관계형 데이터베이스에서 태그 기능을 사용하려면 적어도 2개의 테이블이 추가돼야 한다.  
> 태그 테이블, 태그-게시물 테이블이다.

```redis
127.0.0.1:6379> SADD post:47:tags IT REDIS DataStore
3
127.0.0.1:6379> SADD post:22:tags IT python
2
127.0.0.1:6379> SADD post:53:tags DataStore IT MySQL
3
```

특정 게시물이 어떤 태그와 연관돼 있는지 뿐만 아니라 특정한 태그를 포함한 게시물들도 확인하기 위해서는 태그를 기준으로 하는 `set`에도 데이터를 넣어주면 그 기능을 쉽게 구현할 수 있다.
```redis
// 53번 게시물에 태그를 등록하면서, 각 태그 set에도 53번 게시물을 등록한다.
127.0.0.1:6379> SADD post:53:tags DataStore IT MySQL
3
127.0.0.1:6379> SADD tag:DataStore:posts 53
1
127.0.0.1:6379> SADD tag:IT:posts 53
1
127.0.0.1:6379> SADD tag:MySQL:posts 53
1
```

<br>

만약 IT와 DataStore 태그를 모두 포함하는 게시물을 확인하고 싶으면 교집합을 확인하는 `SINTER` 커맨드를 사용하면 된다.
```redis
127.0.0.1:6379> SINTER tag:IT:posts tag:DataStore:posts
47
53
```

<br>

만약 이 기능을 관계형 데이터베이스를 이용해 구현한다면 약간 까다로울 수 있다.  
태그-포스트 관계형 테이블을 만드는 것이 일반적이다.  

|  post_id  |   tag_id    |
|:---------:|:-----------:|
|    47     |     IT      |
|    47     |    REDIS    |
|    47     |  DataStore  |
|    22     |     IT      |
|    22     |   Python    |
|    53     |  DataStore  |
|    53     |    MySQL    |
|    53     |     IT      |

```sql
SELECT post_id 
FROM tag_posts 
WHERE tag_id IN ('IT', 'DataStore')
GROUP BY post_id
HAVING COUNT(tag_id) = 2;
```
관계형 데이터베이스에서 `group by - having` 절을 사용하면 검색하는 테이블의 크기에 따라 데이터베이스 자체에 부하를 발생시킬 수 있다.


<br>

## ✅ 랜덤 데이터 추출
> 보통 관계형 데이터베이스에서 랜덤 데이터 추출을 사용할 때에는 `ORDER BY RAND()` 함수를 많이 사용한다.  
> 조건 절에 맞는 모든 행을 읽은 뒤, 임시 테이블에 넣어 정렬한 다음 랜덤으로 `limit`에 해당할 때까지 데이터를 추출한다.  
> 데이터가 1만 건 이상일 경우 이와 같은 쿼리는 성능이 나빠지게 돼 굉장히 부하가 많이 가는 방법일 수 있다.

레디스를 사용하면 O(1)의 시간 복잡도를 이용해 랜덤한 데이터를 추출할 수 있다.

`RANDOMKEY`: 레디스에 저장된 전체 키 중 하나를 무작위로 반환한다. 
보통 하나의 레디스 인스턴스에 한 가지 종류의 데이터만 저장하지는 않기 때문에 이와 같은 랜덤 키 추출은 별로 의미가 없을 수 있다.
```redis
127.0.0.1:6379> RANDOMKEY
set:111
127.0.0.1:6379> RANDOMKEY
myset
```

<br>

`HRANDFIELD`: `hash`에 저장된 아이템 중 랜덤한 아이템 추출  
`SRANMEMBER`: `set`에 저장된 아이템 중 랜덤한 아이템 추출  
`ZRANDMEMBER`: `sorted set`에 저장된 아이템 중 랜덤한 아이템 추출  

```redis
// User:hash 셋팅
127.0.0.1:6379> HSET User:hash id:38274 garimoo id:134 SSorryry id:4615 Jinnji
3

// 랜덤 아이템 하나 추출
127.0.0.1:6379> HRANDFIELD User:hash
id:38274

// COUNT 옵션 지정 1개 추출하되, 값도 함께
127.0.0.1:6379> HRANDFIELD User:hash 1 WITHVALUES
id:134
SSorryry

// 랜덤 아이템 2개 추출
127.0.0.1:6379> HRANDFIELD User:hash 2
id:38274
id:4615

// COUNT 옵션 지정 랜덤 아이템 중복 허용 2개 추출
// 음수면 중복 반환이다.
127.0.0.1:6379> HRANDFIELD User:hash -2
id:134
id:38274
127.0.0.1:6379> HRANDFIELD User:hash -2
id:134
id:4615
127.0.0.1:6379> HRANDFIELD User:hash -2
id:4615
id:4615
```

`SRANMEMBER`, `ZRANDMEMBER` 커맨드도 마찬가지로 `COUNT` 옵션을 양수와 음수로 반환시킨다. 


<br>

## ✅ 레디스에서의 다양한 카운팅 방법

### ❗️좋아요 처리하기
실시간 트래픽이 굉장히 많은 사이트라면
1. 하나의 뉴스 댓글에 좋아요가 눌리는 일은 1초에 몇만 개 이상 발생할 수 있다.  
  ➡ 좋아요를 누를 때마다 관계형 데이터베이스 테이블의 특정 행에서 좋아요 개수 데이터를 증가시키는 일은 데이터베이스에 직접적인 영향을 끼칠 수 있다.
2. 하나의 유저는 같은 댓글에 한 번씩만 좋아요를 누를 수 있어야 한다.  
  ➡ 어떤 유저가 어떤 댓글에 좋아요를 눌렀는지의 데이터 또한 처리할 수 있어야 한다.

<br>

댓글 id를 기준으로 `set`을 생성한 뒤, 좋아요를 누른 유저의 id를 `set`에 저장하면 중복 없이 데이터를 저장할 수 있다.

```shell
# 각 댓글마다 좋아요를 누른 유저 id set에 저장
127.0.0.1:6379> SADD comment-like:12554 25 345 967
3
127.0.0.1:6379> SADD comment-like:19967 508 86 167 816
4

# 이미 있는 유저 id는 저장 X
127.0.0.1:6379> SADD comment-like:12554  967
0
127.0.0.1:6379> SMEMBERS comment-like:12554
25
345
967

# 댓글별로 좋아요를 누른 수 조회
127.0.0.1:6379> SCARD comment-like:12554
3
```

<br>

### ❗️ 읽지 않은 메시지 수 카운팅하기
채팅 애플리케이션에서 사용자가 속한 채널별로 읽지 않은 메시지를 카운팅하고 관리하려고 한다.
- 채팅 메시지가 도착할 때마다 바로 관계형 데이터베이스를 업데이트하는 대신 데이터를 레디스와 같은 인메모리 데이터베이스에 일시적으로 저장한 뒤 필요한 시점에 한꺼번에 업데이트하는 방식을 사용   
  ➡ 관계형 데이터베이스의 부하를 최소화하고 성능을 향상시키고자 한다.
- 앞선 좋아요 예제와는 다르게, 채팅의 내용을 확인하거나 중복된 데이터를 고려할 필요 없다.  
  ➡ 단순히 채널에 새로 추가된 메시지의 개수를 확인하면 된다.

<br>

```shell
# user:123이 각 채널별로 받은 메시지 hash에 저장
127.0.0.1:6379> HSET user:123 channel:4234 3 channel:3135 27 channel:1239 128
3
# user:123 hash 조회
127.0.0.1:6379> HGETALL user:123
channel:4234
3
channel:3135
27
channel:1239
128

# user:234가 각 채널별로 받은 메시지 hash에 저장
127.0.0.1:6379> HSET user:234 channel:1123 223 channel:4234 0
2
# user:234 hash 조회
127.0.0.1:6379> HGETALL user:234
channel:1123
223
channel:4234
0

# user:345를 입력하려고 했으나 잘못 입력
127.0.0.1:6379> HSET user>345 channel:4339 2 channel:1239 42 channel:3299 3 channel:15644 150 channel:342 7
5
# user>345 삭제
127.0.0.1:6379> UNLINK user>345
1
# 삭제된 거 확인
127.0.0.1:6379> HGETALL user>345

# user:345가 각 채널별로 받은 메시지 hash에 저장
127.0.0.1:6379> HSET user:345 channel:4339 2 channel:1239 42 channel:3299 3 channel:15644 150 channel:342 7
5
# user:345 hash 조회
127.0.0.1:6379> HGETALL user:345
channel:4339
2
channel:1239
42
channel:3299
3
channel:15644
150
channel:342
7
```

<br>

새로운 메시지를 수신했다면 `HINCRBY` 커맨드를 통해 늘릴 수 있다.
```shell
# user ID가 234인 사용자가 4234 채널에서 새로운 메시지를 수신했다면
127.0.0.1:6379> HINCRBY user:234 channel:4234 1
1
127.0.0.1:6379> HGETALL user:234
channel:1123
223
channel:4234
1
```

<br>

이미 전송한 메시지를 삭제했다면 `HINCRBY` 커맨드를 사용해 음수값을 입력하여 데이터를 감소시킬 수 있다.
```shell
127.0.0.1:6379> HINCRBY user:123 channel:3135 -1
26
127.0.0.1:6379> HGETALL user:123
channel:4234
3
channel:3135
26
channel:1239
128
```

<br>

### ❗️ DAU 구하기
DAU(Daily Active User)는 하루 동안 서비스에 방문한 사용자의 수를 말한다.  
하루에 여러 번 방문했다 하더라도 한 번으로 카운팅되는 값으로, 실제 서비스를 이용한 사용자의 유니크한 수를 파악할 수 있는 지표다.

> 애플리케이션의 사용자 접근 로그와 같은 접속 로그를 활용해 날마다 배치 처리를 수행하는 방식으로 DAU를 계산할 수 있지만 이런 방식으로는 실시간 데이터는 확인할 수 없다.

<br>

> 앞선 좋아요 예제와 마찬가지로 유저 ID를 `set`에 저장하는 방법은 어떨까?  
> 만약 하루 1,000만 명 이상의 유저가 방문하는 큰 서비스라면 하나의 키 안에 너무 많은 아이템이 저장될 수 있다.  
> ➡ 곧 성능의 저하로 이어질 수 있다.  
> (보통 키 하나당 저장하는 아이템은 최대 200~300만 개까지로 조정할 것을 권장한다.)  

<br>

레디스의 [비트맵](https://github.com/kyeoungchan/note/tree/main/redis/basic/data-structure)을 이용하면 메모리를 효율적으로 줄이면서도 실시간으로 서비스의 DAU를 확인할 수 있다.
- 사용자의 ID는 0 이상의 정숫값이어야 한다.
- 사용자 ID는 `string` 자료 구조에서 하나의 비트로 표현될 수 있다.
  - 1천만 명의 사용자는 1천만 개의 비트로 나타낼 수 있으며, 이는 대략 1.2MB 크기에 해당한다. 
    - `1.2MB * 2^3(bit/B) * 2^10(B/KB) * 2^10(KB/MB)`
    - `= 1.2 * 2^23 bit` 
    - `= 10,066,329.6 bit`

<br>

만약 2025년 11월 16일에 방문한 유저 id가 14라면, 다음과 같이 오프셋을 14로 설정해주면 된다.
```shell
# ID 14 유저 방문
127.0.0.1:6379> SETBIT uv:20251116 14 1
0
# 251116 전체 방문자 수 카운트
127.0.0.1:6379> BITCOUNT uv:20251116
1

# ID 3 유저 방문
127.0.0.1:6379> SETBIT uv:20251116 3 1
0
# 251116 전체 방문자 수 카운트
127.0.0.1:6379> BITCOUNT uv:20251116
2
```

<br>

비트맵에서 `BITOP` 커맨드를 사용하면 `AND`, `OR`, `XOR`, `NOT` 연산을 할 수 있어, 레디스 서버에서 바로 계산된 결과를 가져올 수 있다.  
➡ 개별 비트를 가져와 서버에서 처리하는 번거로움을 줄여줄 수 있다.

```shell
# 251101 방문 유저 셋팅
# 1100 1000 1000 0010
127.0.0.1:6379> BITFIELD uv:20251101 SET u1 1 1 SET u1 7 1 SET u1 11 1 SET u1 14 1 SET u1 15 1
0
0
0
0
0
# 총 5명 방문
127.0.0.1:6379> BITCOUNT uv:20251101
5

# 251102 방문 유저 셋팅
# 0100 0011 1001 1000
127.0.0.1:6379> BITFIELD uv:20251102 SET u1 3 1 SET u1 4 1 SET u1 7 1 SET u1 8 1 SET u1 9 1 SET u1 14 1
0
0
0
0
0
0
# 총 6명 방문
127.0.0.1:6379> BITCOUNT uv:20251102
6

# 251103 방문 유저 셋팅
# 0100 1000 1000 1001
127.0.0.1:6379> BITFIELD uv:20251103 SET u1 0 1 SET u1 3 1 SET u1 7 1 SET u1 11 1 SET u1 14 1
0
0
0
0
0
# 총 5명 방문
127.0.0.1:6379> BITCOUNT uv:20251103
5

# 251101~251103까지 모두 방문한 유저 event:202511에 저장
127.0.0.1:6379> BITOP AND event:202511 uv:20251101 uv:20251102 uv:20251103
2
```

<br>

## ✅️ `hyperloglog`를 이용한 애플리케이션 미터링
> 클라우드 환경에서 미터링은 중요한 과제가 되었다.  
> Pay as you go, 즉 서비스를 사용한 만큼 지불하는 것이 클라우드 컴퓨팅의 특성이다.  
> 따라서 사용자가 얼마나 서비스를 사용했는지 정확하게 측정할 수 있어야 한다.

미터링 솔루션은 사용자의 서비스 사용 내역을 이용하기 때문에 대용량 데이터를 처리할 수 있어야 한다.  
➡ 미터링 솔루션은 높은 처리량과 낮은 대기 시간을 가져야 한다.  

<br>

예를 들어, 서버와 클라이언트에서 발생하는 로그를 수집하고 인덱싱해 사용자가 특정 로그를 검색하고 조회할 수 있는 서비스를 클라우드 환경에서 제공한다고 생각해보자.  
로그를 수집할 때마다 서비스의 API를 호출하고, 하나의 API 호출마다 건별로 과금을 매기는 정책이 있다면 사용자별 API 호출 횟수를 카운팅해야 한다.

<br>

다음 조건을 만족한다면 레디스의 [`hyperloglog`](https://github.com/kyeoungchan/note/tree/main/redis/basic/data-structure)를 사용하는 것을 고려해볼 수 있다.
- 집합 내의 유일한 데이터의 개수를 카운팅해야 한다.
- 1% 미만의 오차는 허용이 가능하다.
- 카운팅할 때 사용한 정확한 데이터를 다시 확인하지 않아도 된다.

저장된 값을 다시 확인하지 않아도 되는 경우라서 `hyperloglog`를 이용할 수 있다면 최소한의 메모리만을 사용해 중복되지 않은 데이터의 개수를 계산할 수 있다.
```shell
# 25년 11월 유저 ID가 245인 유저의 호출 횟수 저장 및 조회
127.0.0.1:6379> PFADD 202511:user:245 49483
1
127.0.0.1:6379> PFADD 202511:user:245 32714
1
127.0.0.1:6379> PFADD 202511:user:245 49483
0

# 같은 값을 저장해도 2개가 조회된다.
127.0.0.1:6379> PFCOUNT 202511:user:245
2
```

`hyperloglog`는 `set`과 비슷하지만 저장되는 용량은 12KB로 고정되기 때문에 공간을 굉장히 효율적으로 사용할 수 있다는 장점을 갖고 있다.

`PFMERGE` 커맨드를 이용하면 여러 개의 `hyperloglog`를 합칠 수 있으므로 분기별 또는 연도별 합산 데이터를 간편하게 계산할 수 있다.
```shell
127.0.0.1:6379> PFMERGE 2025:user:245 202511:user:245 202512:user:245
OK
127.0.0.1:6379> PFCOUNT 2025:user:245
2
```

<br>

## ✅️ `Geospatial Index`를 이용한 위치 기반 애플리케이션 개발
### ❗️ 위치 데이터에 대해서
위치 데이터는 주로 경도와 위도(x,y) 좌표 쌍으로 표현된다.  
사용자의 위치가 실시간으로 변할 때, 데이터를 신속하게 저장하고 처리할 수 있는 데이터 저장소는 다음과 같은 기능을 제공해야 한다.
- 사용자의 현재 위치 파악
- 사용자의 이동에 따른 실시간 변동 위치 업데이트
- 사용자의 위치를 기준으로 근처의 장소 검색
 
<br>

모든 사용자의 정보를 1초마다 업데이트한다고 가정하면 사용자의 증가에 따른 위치 데이터는 몇십 배로 증가하게 된다.  
또한 위치 데이터끼리의 연산(사용자 근처의 맛집 검색)은 위치 데이터를 가공해야 하는 것이기 때문에 까다롭게 처리될 수 있다.

### ❗️ 레디스에서의 위치 데이터
레디스는 [`geo` 자료 구조](https://github.com/kyeoungchan/note/tree/main/redis/basic/data-structure)를 통해 처리할 수 있다.
- 다른 자료 구조와 마찬가지로 모든 데이터는 메모리에 저장된다.
- 공간 데이터를 활용한 연산 역시 메모리에서 빠르게 계산될 수 있다.
  - 관계형 데이터베이스의 경우, 위치 데이터를 처리할 때 데이터를 단순히 저장할 뿐이고, 실제 데이터 가공 및 처리 과정은 저장소 외부에서 이루어진다.
  - 레디스를 활용하면 데이터 저장뿐만 아니라 실시간 위치 연산을 직접 수행할 수 있다.


<br>

[`geo set`](https://github.com/kyeoungchan/note/tree/main/redis/basic/data-structure): 위치 공간 관리에 특화된 테이터 구조로, 이 데이터는 내부적으로 `sorted set` 구조로 저장된다.  
➡ 경도, 위도, 아이템 이름 순으로 데이터가 정렬되어 저장된다.

```shell
# user 142 위치 데이터 추가
127.0.0.1:6379> GEOADD user 50.07146286003341 14.41449645417485 142
1

# 프라하의 맛집 ukalendu 위치 데이터 추가
127.0.0.1:6379> GEOADD restaurant 50.07146286003341 14.4144964541785 ukalendu
1

# 저장된 데이터 GEOPOS 커맨드로 조회
127.0.0.1:6379> GEOPOS restaurant ukalendu
50.071464478969574
14.414496646549033
```

<br>

```shell
# FROMLONLAT 옵션 사용하여 1km 이내 식당 찾기
127.0.0.1:6379> GEOSEARCH restaurant FROMLONLAT 50.06824582815170288 14.41818466583587366 byradius 1 km
ukalendu
```
- `FROMLONLAT` 옵션을 이용해 직접 경도와 위도를 지정한 뒤, 해당 위치 근처 1km 내의 데이터를 검색했다.  
- 동일한 데이터 세트 내에서 검색하는 경우 `FROMMEMBER` 옵션을 이용하면 위도와 경도를 직접 입력하지 않고도 원하는 데이터를 찾을 수 있다.

```shell
# 만약 ukalendu2라는 2호점이 생겼다고 가장하자.(프라하에 2호점 식당이 실제로 차리는지는 묻지 말자)
127.0.0.1:6379> GEOADD restaurant 50.0682458281517028 14.4181846658358736 ukalendu2
0

# ukalendu를 기준으로 가로 4km, 세로 2km로 그렸을 때 restaurant가 다음과 같이 2개가 검색된다.
127.0.0.1:6379> GEOSEARCH restaurant FROMMEMBER ukalendu BYBOX 4 2 KM
ukalendu
ukalendu2
```

> `BYBOX` 옵션을 사용할 때 주의해야할 점은 `width`와 `height`를 설정하면 검색 범위가 기준점을 중심으로 가로 `width`, 세로 `height` 만큼의 거리를 포함하는 직사각형 영역으로 결정된다는 점이다.  
> `BYRADIUS`는 기준점을 중심으로 거리지만, `BYBOX`는 직사각형을 그리고 영역을 찾는다는 점에서 다르다.


<br>

**참고 자료**  
[개발자를 위한 레디스](https://product.kyobobook.co.kr/detail/S000210785682)