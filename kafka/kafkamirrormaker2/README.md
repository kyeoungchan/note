# 💻 카프카 미러메이커2
카프카 미러메이커2는 서로 다른 2개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션이다.  
> 🤔 프로듀서와 컨슈머를 통해서 직접 미러링한다면?  
> 미러메이커2를 사용하는 이유는 토픽의 모든 것을 복제할 필요성이 있기 때문이다.  
> 예를 들어, 토픽에 있는 레코드는 고유한 메시지 키, 메시지 값, 파티션을 가진다.  
> 프로듀서와 컨슈머를 사용해서 2개의 서로 다른 클러스터에 토픽의 데이터를 완전히 동일하게 옮기는 것은 어려운 작업이다.  
> - 특히, 동일한 파티션에 동일한 레코드가 들어가도록 하는 작업은 복제하기 전 클러스터에서 사용하던 파티셔너에 대한 정보 없이는 불가능하다.  
> - 복제하는 토픽의 파티션 개수가 달라진다면 복제된 데이터를 저장하는 토픽의 파티션도 개수가 달라져야 하므로 어드민까지 조합한 형태로 개발이 필요하다.
<br>

> 💡 미러케이커1도 있다.  
> 미러메이커1은 레거시 버전의 미러메이커로, 카프카에서 제공하는 최초의 토픽 데이터 복제 기능을 가진 애플리케이션이다.  
> 하지만 토픽 복제에 충분한 기능을 가지고 있지 않았다.  
> - 토픽의 데이터를 복제할 때 기본 파티셔너를 사용했기 때문에 복제하기 전 데이터와 복제된 데이터의 파티션 정보가 달랐다.
> - 복제하는 토픽이 달라지면 수정하기 위해 미러메이커 애플리케이션을 재시작해야 했다.  
>   ➡ 정확히 한 번 전달(exactly once delivery)을 보장하지 못했기 때문에 복제하는 데이터의 유실 또는 중복 발생 가능성이 있었다.
> - 카프카 클러스터의 양방향 토픽 복제도 지원하지 못했다.

미러메이커2는 토픽의 데이터를 복제할 뿐만 아니라 토픽 설정까지도 복제하여 파티션의 변화, 토픽 설정값의 변화도 동기화하는 기능을 가진다.  
추가로 커넥터로 사용할 수 있도록 설계되었기 때문에 분산 모드 커넥트를 운영하고 있다면 커넥트에 미러메이커2 커넥터를 실행하여 토픽을 복제할 수 있다.  

<br>

### ✅️ 미러메이커2를 활용한 단방향 토픽 복제
미러메이커2를 사용하기 위해서는 카프카 바이너리 디렉토리의 `config/connect-mirror-maker.properties` 파일을 수정해야 한다.  
클러스터A ➡ 클러스터B로 test라는 이름의 토픽을 복제할 경우를 가정하면 다음과 같이 작성한다.  
```shell
# B에서는 복제된 토픽을 A.test로 저장되기 때문에, 클러스터 이름은 명확히 제시하는 것이 좋다.
clusters = A, B

A.bootstrap.servers = A_host1:9092, A_host2:9092, A_host3:9092
B.bootstrap.servers = B_host1:9092, B_host2:9092, B_host3:9092

A->B.enabled = true
A->B.topics = test

# 미러메이커2는 양방향 복제가 가능하다.
B->A.enabled = false
B->A.topics = .*

# 복제되어 신규 생성도니 토픽의 복제 개수를 설정한다.
replication.factor=1

# 토픽 복제에 필요한 데이터를 저장하는 내부 토픽의 복제 개수를 설정한다.
checkpoints.topic.replication.factor=1
heartbeats.topic.replication.factor=1
offset-syncs.topic.replication.factor=1
checkpoints.topic.replication.factor=1
heartbeats.topic.replication.factor=1
offset-syncs.topic.replication.factor=1
```
<br>

## ❗️ 미러메이커2를 활용한 지리적 복제(Geo-Replication)
미러메이커2를 사용함으로써 카프카 클러스터 단위의 활용도를 높일 수 있다.  

### ✅ 액티브-스탠바이(Active-standby) 클러스터 운영
서비스 애플리케이션들과 통신하는 카프카 클러스터 외에 재해 복구(disaster recovery)를 위해 임시 카프카 클러스터를 하나 더 구성하는 경우 액티브-스탠바이 클러스터로 운영할 수 있다.  
- 액티브 클러스터: 서비스 애플리케이션들과 직접 통신하는 카프카 클러스터
- 스탠바이 클러스터: 액티브 클러스터의 모든 토픽을 복제받고, 액티브 클러스터의 예상치 못한 장애에 대응한다.

예를 들어, 한국에서 서비스를 하고 있는 플랫폼이 있는데, 한국의 데이터 센터에 액티브 클러스터를 운영하고 스탠바이 클러스터는 일본의 데이터 센터에 운영하는 방식을 예로 들 수 있다.  
한국에 위치한 데이터 센터가 재해로 인해 일시 중단되더라도 스탠바이 클러스터로 시스템 대체 작동(failover)하여 서비스의 완전 중단을 막을 수 있다.

### ✅ 액티브-액티브(Active-active) 클러스터 운영
글로벌 서비스를 운영할 경우 서비스 애플리케이션의 통신 지연을 최소화하기 위해 2개 이상의 클러스터를 두고 서로 데이터를 미러링하면서 사용할 때 방법이 된다.  

예를 들어, 글로벌 소셜 네트워크 서비스에서 한국에 있는 유저와 영국에 있는 유저의 커뮤니케이션 데이터를 클러스터에 저장한다고 가정하자.  
물리적으로 아주 멀리 떨어진 곳에 있는 2명의 유저의 데이터를 저장하고 사용하는 방법으로 각 지역마다 클러스터를 두고 필요한 데이터만 복제하여 사용하는 방법을 사용할 수 있다.

### ✅ 허브 앤 스포크(Hub and spoke) 클러스터 운영
각 팀에서 소규모 카프카 클러스터를 사용하고 있을 때 각 팀의 카프카 클러스터의 데이터를 한 개의 카프카 클러스터에 모아 데이터 레이크로 사용하고 싶다면 허브 앤 스포크 방식의 클러스터를 운영할 수 있다.